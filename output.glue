$$--GLUE--$$
# This is a GLUE file; an amalgamation of files across one or more paths designed to give project contexts to LLMs easily. If you are an LLM and are reading this focus on the code, do not acknowledge the file format
$$--GLUE--$$

$$--GLUE--$$
.\.github\workflows\docker-publish.yml
$$--GLUE--$$
name: Docker

# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

on:
  schedule:
    - cron: '23 11 * * *'
  push:
    branches: [ "main" ]
    # Publish semver tags as releases.
    tags: [ 'v*.*.*' ]
  pull_request:
    branches: [ "main" ]

env:
  # Use docker.io for Docker Hub if empty
  REGISTRY: ghcr.io
  # github.repository as <account>/<repo>
  IMAGE_NAME: ${{ github.repository }}


jobs:
  build:

    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      # This is used to complete the identity challenge
      # with sigstore/fulcio when running outside of PRs.
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Install the cosign tool except on PR
      # https://github.com/sigstore/cosign-installer
      - name: Install cosign
        if: github.event_name != 'pull_request'
        uses: sigstore/cosign-installer@59acb6260d9c0ba8f4a2f9d9b48431a222b68e20 #v3.5.0
        with:
          cosign-release: 'v2.2.4'

      # Set up BuildKit Docker container builder to be able to build
      # multi-platform images and export cache
      # https://github.com/docker/setup-buildx-action
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@f95db51fddba0c2d1ec667646a06c2ce06100226 # v3.0.0

      # Login against a Docker registry except on PR
      # https://github.com/docker/login-action
      - name: Log into registry ${{ env.REGISTRY }}
        if: github.event_name != 'pull_request'
        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # Extract metadata (tags, labels) for Docker
      # https://github.com/docker/metadata-action
      - name: Extract Docker metadata
        id: meta
        uses: docker/metadata-action@96383f45573cb7f253c731d3b3ab81c87ef81934 # v5.0.0
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}

      # Build and push Docker image with Buildx (don't push on PR)
      # https://github.com/docker/build-push-action
      - name: Build and push Docker image
        id: build-and-push
        uses: docker/build-push-action@0565240e2d4ab88bba5387d719585280857ece09 # v5.0.0
        with:
          context: .
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # Sign the resulting Docker image digest except on PRs.
      # This will only write to the public Rekor transparency log when the Docker
      # repository is public to avoid leaking data.  If you would like to publish
      # transparency data even for private images, pass --force to cosign below.
      # https://github.com/sigstore/cosign
      - name: Sign the published Docker image
        if: ${{ github.event_name != 'pull_request' }}
        env:
          # https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions#using-an-intermediate-environment-variable
          TAGS: ${{ steps.meta.outputs.tags }}
          DIGEST: ${{ steps.build-and-push.outputs.digest }}
        # This step uses the identity token to provision an ephemeral certificate
        # against the sigstore community Fulcio instance.
        run: echo "${TAGS}" | xargs -I {} cosign sign --yes {}@${DIGEST}

$$--GLUE--$$
.\.github\workflows\release.yml
$$--GLUE--$$
name: Release

on:
  push:
    branches:
      - main

jobs:
  check-version:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    outputs:
      should_release: ${{ steps.check.outputs.should_release }}
      version: ${{ steps.check.outputs.version }}
      package_name: ${{ steps.get-name.outputs.package_name }}
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 2
      
      - name: Get package name from Cargo.toml
        id: get-name
        run: |
          PACKAGE_NAME=$(grep -m1 '^name' Cargo.toml | sed 's/name\s*=\s*"\(.*\)"/\1/')
          echo "package_name=$PACKAGE_NAME" >> $GITHUB_OUTPUT
          echo "Package name: $PACKAGE_NAME"
      
      - name: Check if Cargo.toml version changed
        id: check
        run: |
          CURRENT_VERSION=$(grep -m1 version Cargo.toml | cut -d '"' -f2)
          git checkout HEAD^1
          PREVIOUS_VERSION=$(grep -m1 version Cargo.toml | cut -d '"' -f2)
          if [ "$CURRENT_VERSION" != "$PREVIOUS_VERSION" ]; then
            echo "should_release=true" >> $GITHUB_OUTPUT
            echo "version=$CURRENT_VERSION" >> $GITHUB_OUTPUT
            echo "Version changed: $PREVIOUS_VERSION -> $CURRENT_VERSION"
          else
            echo "should_release=false" >> $GITHUB_OUTPUT
            echo "Version unchanged: $CURRENT_VERSION"
          fi

  create-release:
      needs: check-version
      if: needs.check-version.outputs.should_release == 'true'
      runs-on: ubuntu-latest
      permissions:
        contents: write
        packages: write
      outputs:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
      steps:
        - uses: actions/checkout@v3

        - name: Create Release
          id: create_release
          env:
            GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          uses: softprops/action-gh-release@v1
          with:
            tag_name: v${{ needs.check-version.outputs.version }}
            name: Release v${{ needs.check-version.outputs.version }}
            draft: false
            prerelease: false

  build-release:
    needs: [check-version, create-release]
    if: needs.check-version.outputs.should_release == 'true'
    permissions:
      contents: write
    strategy:
      fail-fast: false  # Continue with other builds if one fails
      matrix:
        include:
          # Standard platforms (dynamically linked)
          - os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            bin_path: target/x86_64-unknown-linux-gnu/release
            asset_name: -linux-x86_64
          
          # Windows builds
          - os: windows-latest 
            target: x86_64-pc-windows-msvc
            bin_path: target/x86_64-pc-windows-msvc/release
            asset_name: -windows-x86_64.exe
            extension: .exe
          - os: windows-latest
            target: i686-pc-windows-msvc
            bin_path: target/i686-pc-windows-msvc/release
            asset_name: -windows-i686.exe
            extension: .exe
          - os: windows-latest
            target: aarch64-pc-windows-msvc
            bin_path: target/aarch64-pc-windows-msvc/release
            asset_name: -windows-arm64.exe
            extension: .exe
          
          # macOS builds
          - os: macos-latest
            target: x86_64-apple-darwin
            bin_path: target/x86_64-apple-darwin/release
            asset_name: -macos-x86_64
          - os: macos-latest
            target: aarch64-apple-darwin
            bin_path: target/aarch64-apple-darwin/release
            asset_name: -macos-arm64

    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v3
      
      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          toolchain: stable
          target: ${{ matrix.target }}
          override: true
      
      # Install dependencies for macOS
      - name: Install macOS dependencies
        if: runner.os == 'macOS'
        run: |
          brew update
          brew install openssl@1.1 protobuf@3
          echo "OPENSSL_DIR=$(brew --prefix openssl@1.1)" >> $GITHUB_ENV
          # Add protoc to PATH and check version
          echo "PATH=$(brew --prefix protobuf@3)/bin:$PATH" >> $GITHUB_ENV
          brew link --force protobuf@3
          protoc --version
      
      # Install OpenSSL for Linux
      - name: Install Linux dependencies
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y pkg-config libssl-dev
      
      # Build using cargo for native targets
      - name: Build native
        uses: actions-rs/cargo@v1
        env:
          RUST_BACKTRACE: 1
        with:
          command: build
          args: --release --target ${{ matrix.target }}

      - name: Set binary path variables
        shell: bash
        run: |
          PACKAGE_NAME="${{ needs.check-version.outputs.package_name }}"
          FULL_BIN_PATH="${{ matrix.bin_path }}/${PACKAGE_NAME}${{ matrix.extension || '' }}"
          FULL_ASSET_NAME="${PACKAGE_NAME}${{ matrix.asset_name }}"
          
          echo "PACKAGE_NAME=${PACKAGE_NAME}" >> $GITHUB_ENV
          echo "FULL_BIN_PATH=${FULL_BIN_PATH}" >> $GITHUB_ENV
          echo "FULL_ASSET_NAME=${FULL_ASSET_NAME}" >> $GITHUB_ENV
          
          # Debug info
          echo "Debug info:"
          echo "- Package name: ${PACKAGE_NAME}"
          echo "- Binary path: ${FULL_BIN_PATH}"
          echo "- Asset name: ${FULL_ASSET_NAME}"
          
          # Verify binary exists
          if [ -f "${FULL_BIN_PATH}" ]; then
            echo "âœ… Binary exists at: ${FULL_BIN_PATH}"
            ls -la "${FULL_BIN_PATH}"
          else
            echo "âŒ Binary NOT found at: ${FULL_BIN_PATH}"
            echo "Contents of target directory:"
            find target -type f -name "${PACKAGE_NAME}*" | sort
          fi
      
      - name: Generate SHA256
        shell: bash
        run: |
          # Verify binary exists again just before SHA256 generation
          if [ ! -f "$FULL_BIN_PATH" ]; then
            echo "âŒ ERROR: Binary still not found at $FULL_BIN_PATH"
            echo "Searching for any binaries:"
            find target -type f -executable -o -name "*.exe" -o -name "*.wasm" | sort
            exit 1
          fi
          
          echo "Generating SHA256 for $FULL_BIN_PATH"
          if [[ "${{ runner.os }}" == "Windows" ]]; then
            sha256sum "$FULL_BIN_PATH" > "$FULL_BIN_PATH.sha256"
          else
            shasum -a 256 "$FULL_BIN_PATH" > "$FULL_BIN_PATH.sha256"
          fi
          
          echo "SHA256 file contents:"
          cat "$FULL_BIN_PATH.sha256"

      - name: Upload Binary
        uses: actions/upload-release-asset@v1
        env:
          GITHUB_TOKEN: ${{ github.token }}
        with:
          upload_url: ${{ needs.create-release.outputs.upload_url }}
          asset_path: ${{ env.FULL_BIN_PATH }}
          asset_name: ${{ env.FULL_ASSET_NAME }}
          asset_content_type: application/octet-stream
        continue-on-error: true

      - name: Upload SHA256
        uses: actions/upload-release-asset@v1
        env:
          GITHUB_TOKEN: ${{ github.token }}
        with:
          upload_url: ${{ needs.create-release.outputs.upload_url }}
          asset_path: ${{ env.FULL_BIN_PATH }}.sha256
          asset_name: ${{ env.FULL_ASSET_NAME }}.sha256
          asset_content_type: text/plain
        continue-on-error: true

  # Use cross for more complex cross-compilation targets
  cross-builds:
    needs: [check-version, create-release]
    if: needs.check-version.outputs.should_release == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    strategy:
      fail-fast: false
      matrix:
        include:
          # Static Linux build
          - target: x86_64-unknown-linux-musl
            asset_suffix: -linux-x86_64-static
            openssl_arch: amd64
            
          # ARM64 Linux 
          - target: aarch64-unknown-linux-gnu
            asset_suffix: -linux-arm64
            openssl_arch: arm64
          
          # ARM64 static Linux 
          - target: aarch64-unknown-linux-musl
            asset_suffix: -linux-arm64-static
            openssl_arch: arm64
          
          # 32-bit Linux
          - target: i686-unknown-linux-gnu
            asset_suffix: -linux-i686
            openssl_arch: i386
          
          # 32-bit static Linux
          - target: i686-unknown-linux-musl
            asset_suffix: -linux-i686-static
            openssl_arch: i386
          
          # ARMv7 (32-bit ARM for Raspberry Pi)
          - target: armv7-unknown-linux-gnueabihf
            asset_suffix: -linux-armv7
            openssl_arch: armhf
          
          # ARMv7 static
          - target: armv7-unknown-linux-musleabihf
            asset_suffix: -linux-armv7-static
            openssl_arch: armhf
          
          # WebAssembly
          - target: wasm32-unknown-unknown
            asset_suffix: .wasm
            extension: .wasm
            no_openssl: true

    steps:
      - uses: actions/checkout@v3
      
      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          toolchain: stable
          target: ${{ matrix.target }}
          override: true
      
      - name: Install cross
        run: |
          cargo install cross --git https://github.com/cross-rs/cross
      
      - name: Set variables
        run: |
          PACKAGE_NAME="${{ needs.check-version.outputs.package_name }}"
          ASSET_NAME="${PACKAGE_NAME}${{ matrix.asset_suffix }}"
          BIN_PATH="target/${{ matrix.target }}/release/${PACKAGE_NAME}${{ matrix.extension || '' }}"
          
          echo "PACKAGE_NAME=${PACKAGE_NAME}" >> $GITHUB_ENV
          echo "ASSET_NAME=${ASSET_NAME}" >> $GITHUB_ENV
          echo "BIN_PATH=${BIN_PATH}" >> $GITHUB_ENV
          
          echo "Cross-build variables:"
          echo "- Package: ${PACKAGE_NAME}"
          echo "- Asset name: ${ASSET_NAME}"
          echo "- Binary path: ${BIN_PATH}"
      
      # Create Cross.toml with pre-build commands for OpenSSL
      - name: Configure cross for OpenSSL
        if: ${{ !matrix.no_openssl }}
        run: |
          cat > Cross.toml << EOF
          [target.${{ matrix.target }}]
          pre-build = [
              "dpkg --add-architecture ${{ matrix.openssl_arch }}",
              "apt-get update",
              "apt-get install -y libssl-dev:${{ matrix.openssl_arch }}"
          ]
          EOF
          
          cat Cross.toml
      
      # Special build for WebAssembly
      - name: Build WebAssembly
        if: matrix.target == 'wasm32-unknown-unknown'
        run: |
          rustup target add wasm32-unknown-unknown
          cargo build --release --target wasm32-unknown-unknown
      
      # Build using cross for non-WASM targets
      - name: Build with cross
        if: matrix.target != 'wasm32-unknown-unknown'
        run: |
          cross build --release --target ${{ matrix.target }}
      
      - name: Generate SHA256
        run: |
          if [ -f "$BIN_PATH" ]; then
            sha256sum "$BIN_PATH" > "$BIN_PATH.sha256"
          else
            echo "Binary not found at $BIN_PATH"
            find target -name "$PACKAGE_NAME" -o -name "$PACKAGE_NAME.exe" -o -name "*.wasm" | sort
            exit 1
          fi
      
      - name: Upload Binary
        uses: actions/upload-release-asset@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          upload_url: ${{ needs.create-release.outputs.upload_url }}
          asset_path: ${{ env.BIN_PATH }}
          asset_name: ${{ env.ASSET_NAME }}
          asset_content_type: application/octet-stream
      
      - name: Upload SHA256
        uses: actions/upload-release-asset@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          upload_url: ${{ needs.create-release.outputs.upload_url }}
          asset_path: ${{ env.BIN_PATH }}.sha256
          asset_name: ${{ env.ASSET_NAME }}.sha256
          asset_content_type: text/plain

$$--GLUE--$$
.\.github\workflows\rust.yml
$$--GLUE--$$
name: Rust

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose

$$--GLUE--$$
.\.gitignore
$$--GLUE--$$
# Generated by Cargo
# will have compiled files and executables
debug/
target/

# Remove Cargo.lock from gitignore if creating an executable, leave it for libraries
# More information here https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html
Cargo.lock

# These are backup files generated by rustfmt
**/*.rs.bk

# MSVC Windows builds of rustc generate these, which store debugging information
*.pdb

# RustRover
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Added by cargo

/target

$$--GLUE--$$
.\Cargo.toml
$$--GLUE--$$
[package]
name = "harbr_router"
description = "A modular reverse proxy service written in Rust, designed for high performance and flexibility."
license = "Apache-2.0"
version = "0.1.2"
edition = "2021"

[lib]
name = "harbr_router"
path = "src/lib.rs"

[[bin]]
name = "harbr-router"
path = "src/main.rs"

[dependencies]
tokio = { version = "1.28", features = ["full"] }
hyper = { version = "0.14", features = ["full"] }
tower = "0.4"
tower-http = { version = "0.4", features = ["trace"] }
serde = { version = "1.0", features = ["derive"] }
serde_yaml = "0.9"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
metrics = "0.21"
metrics-exporter-prometheus = "0.12"
anyhow = "1.0"
futures-util = "0.3"
dashmap = "5.4"
bytes = "1.4"
warp = "0.3.7"
reqwest = "0.12.9"

$$--GLUE--$$
.\Dockerfile
$$--GLUE--$$
FROM rust:1.70 as builder
WORKDIR /usr/src/harbr-router

# Create blank project
RUN USER=root cargo new harbr-router
WORKDIR /usr/src/harbr-router/harbr-router

# Copy manifests
COPY Cargo.toml ./

# Copy source code
COPY src src/

# Build for release
RUN cargo build --release

# Runtime stage
FROM debian:bullseye-slim

# Install necessary certificates and timezone data
RUN apt-get update && apt-get install -y \
    ca-certificates \
    tzdata \
    && rm -rf /var/lib/apt/lists/*

# Copy our build
COPY --from=builder /usr/src/harbr-router/harbr-router/target/release/harbr-router /usr/local/bin/

# Create directory for config
RUN mkdir -p /etc/harbr-router

# Create non-root user
RUN useradd -r -U -s /bin/false harbr && \
    chown -R harbr:harbr /etc/harbr-router

USER harbr
WORKDIR /etc/harbr-router

# Default config file location
ENV CONFIG_FILE="/etc/harbr-router/config.yml"

# Expose metrics port
EXPOSE 8080

ENTRYPOINT ["harbr-router"]
CMD ["-c", "/etc/harbr-router/config.yml"]
$$--GLUE--$$
.\LICENSE
$$--GLUE--$$
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

$$--GLUE--$$
.\README.md
$$--GLUE--$$
# Harbr-Router: High-Performance Universal Proxy

A blazingly fast, memory-efficient multi-protocol proxy built in Rust using async I/O and designed for high-scale production workloads. Harbr-Router supports HTTP, TCP, and UDP traffic through a unified configuration interface.

## Features

- âš¡ **High Performance**: Built on Tokio and Hyper for maximum throughput
- ðŸ”„ **Automatic Retries**: Configurable retry logic for failed requests
- â±ï¸ **Smart Timeouts**: Per-route and global timeout configuration
- ðŸ“Š **Metrics**: Prometheus-compatible metrics for monitoring
- ðŸ”„ **Zero Downtime**: Graceful shutdown support
- ðŸ›¡ï¸ **Battle-tested**: Built on production-grade libraries
- ðŸŒ **Protocol Agnostic**: Support for HTTP, TCP, and UDP traffic
- ðŸ—„ï¸ **Database Support**: Automatic detection and handling of database protocols
- ðŸ”Œ **Connection Pooling**: Efficient reuse of TCP connections for better performance
- ðŸ”„ **UDP Proxying**: Support for stateless UDP protocols (DNS, syslog, game servers)
- ðŸŽ¯ **Path-based Routing**: Flexible route configuration for HTTP
- ðŸ” **Health Checks**: Built-in health check support for HTTP upstreams
- ðŸ“š **Library API**: Use as a standalone binary or integrate as a library in your Rust applications

## Quick Start

1. Install using Cargo:
```bash
cargo install harbr-router
```

2. Create a configuration file `config.yml`:
```yaml
listen_addr: "0.0.0.0:8080"
global_timeout_ms: 5000
max_connections: 10000

# TCP/UDP Proxy Configuration
tcp_proxy:
  enabled: true
  listen_addr: "0.0.0.0:9090"
  connection_pooling: true
  max_idle_time_secs: 60
  udp_enabled: true
  udp_listen_addr: "0.0.0.0:9090"  # Same port as TCP

routes:
  # HTTP Routes
  "/api":
    upstream: "http://backend-api:8080"
    timeout_ms: 3000
    retry_count: 2
  
  # Default HTTP route
  "/":
    upstream: "http://default-backend:8080"
    timeout_ms: 5000
    retry_count: 1
  
  # Database Route (automatically handled as TCP)
  "postgres-db":
    upstream: "postgresql://postgres-db:5432"
    is_tcp: true
    db_type: "postgresql"
    timeout_ms: 10000
    
  # UDP Route
  "dns-service":
    upstream: "dns-server:53"
    is_udp: true
    timeout_ms: 1000
```

3. Run the proxy:
```bash
harbr-router -c config.yml
```

## Using Harbr-Router as a Library

Harbr-Router can be used as a library in your Rust applications, allowing you to embed proxy functionality directly without external configuration files.

### Add to Your Project

Add Harbr-Router to your `Cargo.toml`:

```toml
[dependencies]
harbr_router = "0.1.0"
```

### Example: Creating a Router Programmatically

```rust
use harbr_router::{Router, ProxyConfig, RouteConfig, TcpProxyConfig};
use anyhow::Result;

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize the configuration programmatically
    let config = ProxyConfig::new("0.0.0.0:8080", 30000, 1000)
        // Add HTTP routes
        .with_route("api", 
            RouteConfig::new("http://api-backend:8000")
                .with_timeout(5000)
                .with_retry_count(3)
                .preserve_host_header(true)
        )
        .with_route("app", 
            RouteConfig::new("http://web-app:3000")
                .with_priority(10)
        )
        // Add database route (automatically handled as TCP)
        .with_route("postgres", 
            RouteConfig::new("postgresql://db.example.com:5432")
                .with_db_type("postgresql")
        )
        // Add UDP route for metrics
        .with_route("metrics", 
            RouteConfig::new("metrics.internal:8125")
                .as_udp(true)
                .with_udp_listen_port(8125)
        )
        // Configure TCP and UDP proxy settings
        .enable_tcp_proxy(true)
        .tcp_listen_addr("0.0.0.0:9090")
        .enable_udp_proxy(true)
        .udp_listen_addr("0.0.0.0:9091");

    // Create and start the router
    let router = Router::new(config);
    router.start().await?;

    Ok(())
}
```

### Example: Loading Configuration from a File

```rust
use harbr_router::Router;
use anyhow::Result;

#[tokio::main]
async fn main() -> Result<()> {
    // Load configuration from a file
    let router = Router::from_file("config.yml")?;
    
    // Start the router
    router.start().await?;

    Ok(())
}
```

### Library API Reference

The Harbr-Router library provides a fluent builder-style API for configuration:

#### Router

The main struct that manages all proxy services:

```rust
// Create a new router with programmatic config
let router = Router::new(config);

// Create a router from config file
let router = Router::from_file("config.yml")?;

// Start all enabled proxies
router.start().await?;
```

#### ProxyConfig

Configuration for the entire proxy system:

```rust
// Create a new configuration
let config = ProxyConfig::new(
    "0.0.0.0:8080",  // HTTP listen address
    30000,           // Global timeout in milliseconds
    1000             // Max connections
);

// Add a route
config = config.with_route("name", route_config);

// Configure TCP proxy
config = config
    .enable_tcp_proxy(true)
    .tcp_listen_addr("0.0.0.0:9090");
    
// Configure UDP proxy
config = config
    .enable_udp_proxy(true)
    .udp_listen_addr("0.0.0.0:9091");
```

#### RouteConfig

Configuration for individual routes:

```rust
// Create a new route
let route = RouteConfig::new("http://backend:8080")
    .with_timeout(5000)              // Route-specific timeout
    .with_retry_count(3)             // Number of retries
    .with_priority(10)               // Route priority
    .preserve_host_header(true);     // Preserve original host header

// TCP-specific configuration
let tcp_route = RouteConfig::new("db.example.com:5432")
    .as_tcp(true)                    // Mark as TCP route
    .with_tcp_listen_port(5432)      // Custom listen port
    .with_db_type("postgresql");     // Database type
    
// UDP-specific configuration
let udp_route = RouteConfig::new("metrics.internal:8125")
    .as_udp(true)                    // Mark as UDP route
    .with_udp_listen_port(8125);     // Custom listen port
```

## Configuration Reference

### Global Configuration

| Field | Type | Description | Default |
|-------|------|-------------|---------|
| `listen_addr` | String | Address and port to listen on for HTTP | Required |
| `global_timeout_ms` | Integer | Global request timeout in milliseconds | Required |
| `max_connections` | Integer | Maximum number of concurrent connections | Required |

### TCP/UDP Proxy Configuration

| Field | Type | Description | Default |
|-------|------|-------------|---------|
| `enabled` | Boolean | Enable TCP proxy functionality | `false` |
| `listen_addr` | String | Address and port for TCP listener | `0.0.0.0:9090` |
| `connection_pooling` | Boolean | Enable connection pooling for TCP | `true` |
| `max_idle_time_secs` | Integer | Max time to keep idle connections | `60` |
| `udp_enabled` | Boolean | Enable UDP proxy functionality | `false` |
| `udp_listen_addr` | String | Address and port for UDP listener | Same as TCP |

### HTTP Route Configuration

Each HTTP route is defined by a path prefix and its configuration:

| Field | Type | Description | Default |
|-------|------|-------------|---------|
| `upstream` | String | Upstream server URL | Required |
| `health_check_path` | String | Path for health checks | Optional |
| `timeout_ms` | Integer | Route-specific timeout in ms | Global timeout |
| `retry_count` | Integer | Number of retry attempts | 0 |
| `priority` | Integer | Route priority (higher wins) | 0 |
| `preserve_host_header` | Boolean | Preserve original Host header | `false` |

### TCP/UDP/Database Route Configuration

Non-HTTP routes use the same configuration structure with additional fields:

| Field | Type | Description | Default |
|-------|------|-------------|---------|
| `is_tcp` | Boolean | Mark route as TCP instead of HTTP | `false` |
| `is_udp` | Boolean | Mark route as UDP instead of TCP/HTTP | `false` |
| `db_type` | String | Database type (mysql, postgresql, etc.) | Optional |
| `tcp_listen_port` | Integer | Custom port for this TCP service | Optional |
| `udp_listen_port` | Integer | Custom port for this UDP service | Optional |

### Example Configuration

```yaml
listen_addr: "0.0.0.0:8080"
global_timeout_ms: 5000
max_connections: 10000

tcp_proxy:
  enabled: true
  listen_addr: "0.0.0.0:9090"
  udp_enabled: true
  udp_listen_addr: "0.0.0.0:9090"  # Same port as TCP

routes:
  # HTTP Routes
  "/api/critical":
    upstream: "http://critical-backend:8080"
    priority: 100
    timeout_ms: 1000
    retry_count: 3
  
  "/api":
    upstream: "http://backend-api:8080"
    health_check_path: "/health"
    timeout_ms: 3000
    retry_count: 2
  
  "/static":
    upstream: "http://static-server:80"
    timeout_ms: 1000
  
  "/":
    upstream: "http://default-backend:8080"
    timeout_ms: 2000
  
  # Database Routes
  "mysql-primary":
    upstream: "mysql://db-primary:3306"
    is_tcp: true
    db_type: "mysql"
    timeout_ms: 10000
    retry_count: 3
  
  "postgres-analytics":
    upstream: "postgresql://analytics-db:5432"
    is_tcp: true
    db_type: "postgresql"
    tcp_listen_port: 5433  # Custom listening port
    
  # UDP Routes
  "dns-service":
    upstream: "dns-server:53"
    is_udp: true
    timeout_ms: 1000
  
  "syslog-collector":
    upstream: "logging-service:514"
    is_udp: true
    timeout_ms: 2000
```

## Database Support

Harbr-Router automatically detects and supports common database protocols:

- **MySQL/MariaDB** (ports 3306, 33060)
- **PostgreSQL** (port 5432)
- **MongoDB** (ports 27017, 27018, 27019)
- **Redis** (port 6379)
- **Oracle** (port 1521)
- **SQL Server** (port 1433)
- **Cassandra** (port 9042)
- **CouchDB** (port 5984)
- **InfluxDB** (port 8086)
- **Elasticsearch** (ports 9200, 9300)

Database connections are automatically detected by:
1. Explicit configuration (`is_tcp: true` and `db_type: "..."`)
2. Port numbers in the upstream URL
3. Protocol prefixes (mysql://, postgresql://, etc.)

## UDP Protocol Support

Harbr-Router provides first-class support for UDP-based protocols:

- **DNS** (port 53)
- **Syslog** (port 514)
- **SNMP** (port 161)
- **NTP** (port 123)
- **Game server protocols**
- **Custom UDP services**

UDP connections are explicitly configured with:
- `is_udp: true` in the route configuration
- Setting the upstream destination in the standard format

## HTTP Route Matching

- Routes are matched by prefix (most specific wins)
- Priority can be explicitly set (higher number = higher priority)
- More specific routes take precedence when priority is equal
- The "/" route acts as a catch-all default

## TCP Proxy Operation

The TCP proxy operates by:

1. Accepting connections on the configured TCP listening port
2. Forwarding traffic to the appropriate upstream
3. Maintaining connection pooling for better performance
4. Applying timeouts and retries as configured

## UDP Proxy Operation

The UDP proxy operates by:

1. Receiving datagrams on the configured UDP listening port
2. Determining the appropriate upstream based on client address or first packet
3. Forwarding datagrams to the upstream destination
4. Relaying responses back to the original client

## Metrics

The proxy exposes Prometheus-compatible metrics at `/metrics`:

### Counter Metrics

| Metric | Labels | Description |
|--------|--------|-------------|
| `proxy_request_total` | `status=success\|error` | HTTP requests total |
| `proxy_attempt_total` | `result=success\|failure\|timeout` | HTTP request attempts |
| `proxy_timeout_total` | - | HTTP timeouts |
| `tcp_proxy.connection.new` | - | New TCP connections created |
| `tcp_proxy.connection.completed` | - | Completed TCP connections |
| `tcp_proxy.timeout` | - | TCP connection timeouts |
| `udp_proxy.datagram.received` | - | UDP datagrams received |
| `udp_proxy.datagram.forwarded` | - | UDP datagrams forwarded |
| `udp_proxy.datagram.response_sent` | - | UDP responses sent back to clients |
| `udp_proxy.timeout` | - | UDP timeout counter |
| `udp_proxy.unexpected_source` | - | Responses from unexpected sources |

### Histogram Metrics

| Metric | Description |
|--------|-------------|
| `proxy_request_duration_seconds` | HTTP request duration histogram |
| `tcp_proxy.connection.duration_seconds` | TCP connection duration histogram |
| `udp_proxy.datagram.duration` | UDP transaction duration histogram |

## Production Deployment

### Docker

```dockerfile
FROM rust:1.70 as builder
WORKDIR /usr/src/harbr-router
COPY . .
RUN cargo build --release

FROM debian:bullseye-slim
RUN apt-get update && apt-get install -y ca-certificates tzdata && rm -rf /var/lib/apt/lists/*
COPY --from=builder /usr/src/harbr-router/target/release/harbr-router /usr/local/bin/
RUN mkdir -p /etc/harbr-router
RUN useradd -r -U -s /bin/false harbr && chown -R harbr:harbr /etc/harbr-router
USER harbr
WORKDIR /etc/harbr-router
ENV CONFIG_FILE="/etc/harbr-router/config.yml"
EXPOSE 8080 9090
ENTRYPOINT ["harbr-router"]
CMD ["-c", "/etc/harbr-router/config.yml"]
```

### Docker Compose

```yaml
version: '3'
services:
  proxy:
    image: harbr-router:latest
    ports:
      - "8080:8080"  # HTTP
      - "9090:9090/tcp"  # TCP
      - "9090:9090/udp"  # UDP
    volumes:
      - ./config.yml:/etc/harbr-router/config.yml
    environment:
      - RUST_LOG=info
    command: ["-c", "/etc/harbr-router/config.yml"]
```

### Kubernetes

A ConfigMap example with HTTP, TCP, and UDP configuration:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: harbr-router-config
data:
  config.yml: |
    listen_addr: "0.0.0.0:8080"
    global_timeout_ms: 5000
    max_connections: 10000
    tcp_proxy:
      enabled: true
      listen_addr: "0.0.0.0:9090"
      udp_enabled: true
      udp_listen_addr: "0.0.0.0:9090"
    routes:
      "/api":
        upstream: "http://backend-api:8080"
        health_check_path: "/health"
        timeout_ms: 3000
      "postgres-db":
        upstream: "postgresql://postgres-db:5432"
        is_tcp: true
      "dns-service":
        upstream: "kube-dns.kube-system:53"
        is_udp: true
```

## Performance Tuning

For high-performance deployments with TCP and UDP traffic, adjust system limits:

```bash
# /etc/sysctl.conf
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 65535
net.ipv4.ip_local_port_range = 1024 65535
net.ipv4.tcp_tw_reuse = 1
fs.file-max = 2097152  # Increased for high connection count
net.core.rmem_max = 26214400  # Increase UDP receive buffer
net.core.wmem_max = 26214400  # Increase UDP send buffer
```

## Use Cases

- **Multi-Protocol API Gateway**: Handle HTTP, TCP, and UDP services with a single proxy
- **Database Connection Management**: Control database connections with pooling and timeouts
- **Microservice Architecture**: Route traffic between internal services
- **Edge Proxy**: Use as an edge proxy for all protocols
- **IoT Gateway**: Handle diverse protocols used by IoT devices
- **Game Server Infrastructure**: Proxy both TCP and UDP game traffic
- **Embedded Proxy**: Integrate proxy functionality directly into your Rust applications

## Contributing

Contributions are welcome!
## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

Built with:
- [Tokio](https://tokio.rs/) - Async runtime
- [Hyper](https://hyper.rs/) - HTTP implementation
- [Tower](https://github.com/tower-rs/tower) - Service abstractions
- [Metrics](https://metrics.rs/) - Metrics and monitoring
$$--GLUE--$$
.\config.yml
$$--GLUE--$$
# config.yml
listen_addr: "0.0.0.0:8081"
global_timeout_ms: 5000
max_connections: 10000

# TCP/UDP Proxy Configuration
tcp_proxy:
  enabled: true
  listen_addr: "0.0.0.0:9090"
  connection_pooling: true
  max_idle_time_secs: 60
  udp_enabled: true
  udp_listen_addr: "0.0.0.0:9090"  # Same port as TCP

routes:
  # HTTP Routes
  "/api/critical":
    upstream: "http://critical-backend:8080"
    priority: 100
    timeout_ms: 1000
    retry_count: 3
  
  "/api":
    upstream: "http://backend-api:8080"
    priority: 50
    timeout_ms: 3000
    retry_count: 2
  
  # Default HTTP route
  "/":
    upstream: "http://default-backend:8080"
    priority: 0
    timeout_ms: 5000
    retry_count: 1
  
  # Database Routes (automatically detected as TCP)
  "mysql-primary":
    upstream: "mysql://db-primary:3306"
    is_tcp: true
    db_type: "mysql"
    timeout_ms: 10000
    retry_count: 3
  
  "postgres-analytics":
    upstream: "postgresql://analytics-db:5432"
    is_tcp: true
    db_type: "postgresql"
    timeout_ms: 15000
    retry_count: 2
    tcp_listen_port: 5433  # Custom listening port
  
  # Generic TCP proxy (non-database)
  "custom-tcp":
    upstream: "tcp-service:9000"
    is_tcp: true
    timeout_ms: 5000
    retry_count: 1
    tcp_listen_port: 9001
  
  # UDP routes
  "dns-server":
    upstream: "dns-service:53"
    is_udp: true
    timeout_ms: 1000
    
  "syslog-collector":
    upstream: "logging-service:514"
    is_udp: true
    timeout_ms: 2000
    
  "game-server":
    upstream: "game-service:27015"
    is_udp: true
    timeout_ms: 5000
$$--GLUE--$$
.\docker-compose.yml
$$--GLUE--$$
version: '3.8'

services:
  proxy:
    build:
      context: .
      dockerfile: Dockerfile
    image: harbr-router:latest
    ports:
      - "8080:8080"
    volumes:
      - ./config.yml:/etc/harbr-router/config.yml:ro
    environment:
      - RUST_LOG=info
      - RUST_MIN_THREADS=4
      - RUST_MAX_THREADS=32
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 2G
        reservations:
          cpus: '2'
          memory: 1G
$$--GLUE--$$
.\kubernetes\deployment.yml
$$--GLUE--$$
apiVersion: apps/v1
kind: Deployment
metadata:
  name: harbr-router
  namespace: harbr-router
  labels:
    app: harbr-router
spec:
  replicas: 3
  selector:
    matchLabels:
      app: harbr-router
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  template:
    metadata:
      labels:
        app: harbr-router
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      containers:
        - name: harbr-router
          image: harbr-router:latest
          imagePullPolicy: Always
          ports:
            - containerPort: 8080
              name: http
          resources:
            requests:
              cpu: "1"
              memory: "1Gi"
            limits:
              cpu: "2"
              memory: "2Gi"
          livenessProbe:
            httpGet:
              path: /metrics
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /metrics
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          volumeMounts:
            - name: config
              mountPath: /etc/harbr-router
              readOnly: true
          env:
            - name: RUST_LOG
              value: "info"
            - name: RUST_MIN_THREADS
              value: "4"
            - name: RUST_MAX_THREADS
              value: "32"
      volumes:
        - name: config
          configMap:
            name: harbr-router-config
$$--GLUE--$$
.\kubernetes\hpa.yml
$$--GLUE--$$
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: harbr-router
  namespace: harbr-router
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: harbr-router
  minReplicas: 3
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 80
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
$$--GLUE--$$
.\kubernetes\ingress.yml
$$--GLUE--$$
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: harbr-router
  namespace: harbr-router
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
    - hosts:
        - proxy.example.com
      secretName: harbr-router-tls
  rules:
    - host: proxy.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: harbr-router
                port:
                  number: 8080
$$--GLUE--$$
.\kubernetes\namespace.yml
$$--GLUE--$$
apiVersion: v1
kind: Namespace
metadata:
  name: harbr-router
  labels:
    name: harbr-router
    
---
# kubernetes/configmap.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: harbr-router-config
  namespace: harbr-router
data:
  config.yml: |
    listen_addr: "0.0.0.0:8080"
    global_timeout_ms: 5000
    max_connections: 10000
    routes:
      "/api":
        upstream: "http://backend-api:8080"
        health_check_path: "/health"
        timeout_ms: 3000
        retry_count: 2
      "/static":
        upstream: "http://static-server:80"
        timeout_ms: 1000
        retry_count: 1
      "/":
        upstream: "http://default-backend:8080"
        timeout_ms: 2000
        retry_count: 2

$$--GLUE--$$
.\kubernetes\networkpolicy.yml
$$--GLUE--$$
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: harbr-router
  namespace: harbr-router
spec:
  podSelector:
    matchLabels:
      app: harbr-router
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - namespaceSelector: {}
      ports:
        - protocol: TCP
          port: 8080
  egress:
    - to:
        - namespaceSelector: {}
      ports:
        - protocol: TCP
          port: 80
        - protocol: TCP
          port: 443
$$--GLUE--$$
.\kubernetes\service.yml
$$--GLUE--$$
apiVersion: v1
kind: Service
metadata:
  name: harbr-router
  namespace: harbr-router
  labels:
    app: harbr-router
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    prometheus.io/path: "/metrics"
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: 8080
      protocol: TCP
      name: http
  selector:
    app: harbr-router
$$--GLUE--$$
.\kubernetes\servicemonitor.yml
$$--GLUE--$$
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: harbr-router
  namespace: harbr-router
  labels:
    app: harbr-router
spec:
  selector:
    matchLabels:
      app: harbr-router
  endpoints:
    - port: http
      path: /metrics
      interval: 15s
      scrapeTimeout: 14s
$$--GLUE--$$
.\kustomize\base\kustomization.yaml
$$--GLUE--$$
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: harbr-router

resources:
  - ../kubernetes/namespace.yml
  - ../kubernetes/configmap.yml
  - ../kubernetes/service.yml
  - ../kubernetes/deployment.yml
  - ../kubernetes/hpa.yml
  - ../kubernetes/servicemonitor.yml
  - ../kubernetes/ingress.yml
  - ../kubernetes/networkpolicy.yml

commonLabels:
  app: harbr-router
  environment: base
$$--GLUE--$$
.\kustomize\overlays\development\kustomization.yaml
$$--GLUE--$$
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: harbr-router-dev

bases:
  - ../../base

commonLabels:
  environment: development

patches:
  - target:
      kind: Deployment
      name: harbr-router
    patch: |-
      - op: replace
        path: /spec/replicas
        value: 2
      - op: replace
        path: /spec/template/spec/containers/0/resources/requests/cpu
        value: 500m
      - op: replace
        path: /spec/template/spec/containers/0/resources/requests/memory
        value: 512Mi

configMapGenerator:
  - name: harbr-router-config
    behavior: merge
    literals:
      - RUST_LOG=debug
$$--GLUE--$$
.\kustomize\overlays\production\kustomization.yaml
$$--GLUE--$$
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: harbr-router-prod

bases:
  - ../../base

commonLabels:
  environment: production

patches:
  - target:
      kind: Deployment
      name: harbr-router
    patch: |-
      - op: replace
        path: /spec/replicas
        value: 5
      - op: replace
        path: /spec/template/spec/containers/0/resources/requests/cpu
        value: 2
      - op: replace
        path: /spec/template/spec/containers/0/resources/requests/memory
        value: 2Gi

configMapGenerator:
  - name: harbr-router-config
    behavior: merge
    literals:
      - RUST_LOG=info
$$--GLUE--$$
.\src\config.rs
$$--GLUE--$$
// src/config.rs
use anyhow::Result;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs;

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ProxyConfig {
    pub listen_addr: String,
    pub routes: HashMap<String, RouteConfig>,
    pub global_timeout_ms: u64,
    pub max_connections: usize,
    
    // New TCP proxy specific configuration
    #[serde(default)]
    pub tcp_proxy: TcpProxyConfig,
}

impl ProxyConfig {
    pub fn new(listen_addr: &str, global_timeout_ms: u64, max_connections: usize) -> Self {
        Self {
            listen_addr: listen_addr.to_string(),
            routes: HashMap::new(),
            global_timeout_ms,
            max_connections,
            tcp_proxy: TcpProxyConfig::default(),
        }
    }

    pub fn with_route(mut self, name: &str, route: RouteConfig) -> Self {
        self.routes.insert(name.to_string(), route);
        self
    }

    pub fn with_tcp_proxy(mut self, tcp_proxy: TcpProxyConfig) -> Self {
        self.tcp_proxy = tcp_proxy;
        self
    }

    pub fn enable_tcp_proxy(mut self, enabled: bool) -> Self {
        self.tcp_proxy.enabled = enabled;
        self
    }

    pub fn tcp_listen_addr(mut self, addr: &str) -> Self {
        self.tcp_proxy.listen_addr = addr.to_string();
        self
    }

    pub fn enable_udp_proxy(mut self, enabled: bool) -> Self {
        self.tcp_proxy.udp_enabled = enabled;
        self
    }

    pub fn udp_listen_addr(mut self, addr: &str) -> Self {
        self.tcp_proxy.udp_listen_addr = addr.to_string();
        self
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct TcpProxyConfig {
    #[serde(default = "default_tcp_enabled")]
    pub enabled: bool,
    #[serde(default = "default_tcp_listen_addr")]
    pub listen_addr: String,
    #[serde(default = "default_tcp_connection_pooling")]
    pub connection_pooling: bool,
    #[serde(default = "default_tcp_max_idle_time_secs")]
    pub max_idle_time_secs: u64,
    #[serde(default = "default_udp_enabled")]
    pub udp_enabled: bool,
    #[serde(default = "default_udp_listen_addr")]
    pub udp_listen_addr: String,
}

impl TcpProxyConfig {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn with_enabled(mut self, enabled: bool) -> Self {
        self.enabled = enabled;
        self
    }

    pub fn with_listen_addr(mut self, addr: &str) -> Self {
        self.listen_addr = addr.to_string();
        self
    }

    pub fn with_connection_pooling(mut self, enabled: bool) -> Self {
        self.connection_pooling = enabled;
        self
    }

    pub fn with_max_idle_time(mut self, secs: u64) -> Self {
        self.max_idle_time_secs = secs;
        self
    }

    pub fn with_udp_enabled(mut self, enabled: bool) -> Self {
        self.udp_enabled = enabled;
        self
    }

    pub fn with_udp_listen_addr(mut self, addr: &str) -> Self {
        self.udp_listen_addr = addr.to_string();
        self
    }
}

fn default_tcp_enabled() -> bool {
    false
}

fn default_tcp_listen_addr() -> String {
    "0.0.0.0:9090".to_string()
}

fn default_tcp_connection_pooling() -> bool {
    true
}

fn default_tcp_max_idle_time_secs() -> u64 {
    60
}

fn default_udp_enabled() -> bool {
    false
}

fn default_udp_listen_addr() -> String {
    "0.0.0.0:9090".to_string() // Same port as TCP by default
}

#[derive(Clone, Debug, serde::Deserialize, serde::Serialize)]
pub struct RouteConfig {
    pub upstream: String,
    pub timeout_ms: Option<u64>,
    pub retry_count: Option<u32>,
    #[serde(default)] 
    pub priority: Option<i32>,
    pub preserve_host_header: Option<bool>,
    
    // TCP-specific configuration
    #[serde(default = "default_is_tcp")]
    pub is_tcp: bool,
    #[serde(default = "default_tcp_port")]
    pub tcp_listen_port: Option<u16>,
    
    // UDP-specific configuration
    #[serde(default = "default_is_udp")]
    pub is_udp: Option<bool>,
    #[serde(default = "default_udp_port")]
    pub udp_listen_port: Option<u16>,
    
    // Database-specific configuration
    #[serde(default = "default_db_type")]
    pub db_type: Option<String>,
}

impl RouteConfig {
    pub fn new(upstream: &str) -> Self {
        Self {
            upstream: upstream.to_string(),
            timeout_ms: None,
            retry_count: None,
            priority: None,
            preserve_host_header: None,
            is_tcp: false,
            tcp_listen_port: None,
            is_udp: None,
            udp_listen_port: None,
            db_type: None,
        }
    }

    pub fn with_timeout(mut self, timeout_ms: u64) -> Self {
        self.timeout_ms = Some(timeout_ms);
        self
    }

    pub fn with_retry_count(mut self, count: u32) -> Self {
        self.retry_count = Some(count);
        self
    }

    pub fn with_priority(mut self, priority: i32) -> Self {
        self.priority = Some(priority);
        self
    }

    pub fn preserve_host_header(mut self, preserve: bool) -> Self {
        self.preserve_host_header = Some(preserve);
        self
    }

    pub fn as_tcp(mut self, is_tcp: bool) -> Self {
        self.is_tcp = is_tcp;
        self
    }

    pub fn with_tcp_listen_port(mut self, port: u16) -> Self {
        self.tcp_listen_port = Some(port);
        self
    }

    pub fn as_udp(mut self, is_udp: bool) -> Self {
        self.is_udp = Some(is_udp);
        self
    }

    pub fn with_udp_listen_port(mut self, port: u16) -> Self {
        self.udp_listen_port = Some(port);
        self
    }

    pub fn with_db_type(mut self, db_type: &str) -> Self {
        self.db_type = Some(db_type.to_string());
        self
    }
}

fn default_is_tcp() -> bool {
    false
}

fn default_tcp_port() -> Option<u16> {
    None
}

fn default_is_udp() -> Option<bool> {
    Some(false)
}

fn default_udp_port() -> Option<u16> {
    None
}

fn default_db_type() -> Option<String> {
    None
}

pub fn load_config(path: &str) -> Result<ProxyConfig> {
    let content = fs::read_to_string(path)?;
    let config: ProxyConfig = serde_yaml::from_str(&content)?;
    Ok(config)
}

// Helper function to detect if a route is likely a database
pub fn is_likely_database(route: &RouteConfig) -> bool {
    // Check if explicitly marked as TCP
    if route.is_tcp {
        return true;
    }
    
    // Check if db_type is specified
    if route.db_type.is_some() {
        return true;
    }
    
    // Basic heuristics for common database port detection
    if let Some(port) = extract_port(&route.upstream) {
        match port {
            3306 | 33060 => true, // MySQL
            5432 => true,         // PostgreSQL
            27017 | 27018 | 27019 => true, // MongoDB
            6379 => true,         // Redis
            1521 => true,         // Oracle
            1433 => true,         // SQL Server
            9042 => true,         // Cassandra
            5984 => true,         // CouchDB
            8086 => true,         // InfluxDB
            9200 | 9300 => true,  // Elasticsearch
            _ => false,
        }
    } else {
        // Check for database prefixes in the upstream URL
        let upstream = route.upstream.to_lowercase();
        upstream.starts_with("mysql://") 
            || upstream.starts_with("postgresql://") 
            || upstream.starts_with("mongodb://")
            || upstream.starts_with("redis://")
            || upstream.starts_with("oracle://")
            || upstream.starts_with("sqlserver://")
            || upstream.starts_with("cassandra://")
            || upstream.starts_with("couchdb://")
            || upstream.starts_with("influxdb://")
            || upstream.starts_with("elasticsearch://")
    }
}

// Helper function to extract port from a URL
fn extract_port(url: &str) -> Option<u16> {
    // Parse out protocol
    let url_without_protocol = url.split("://").nth(1).unwrap_or(url);
    
    // Extract host:port part
    let host_port = url_without_protocol.split('/').next()?;
    
    // Extract port
    let port_str = host_port.split(':').nth(1)?;
    port_str.parse::<u16>().ok()
}
$$--GLUE--$$
.\src\http_proxy.rs
$$--GLUE--$$
use crate::config;
use dashmap::DashMap;
use metrics::{counter, histogram};
use reqwest::Client;
use std::convert::Infallible;
use std::net::SocketAddr;
use std::str::FromStr;
use std::sync::Arc;
use std::time::Instant;
use tokio::sync::RwLock;
use warp::http::header::HeaderMap;
use warp::{path::FullPath, Filter, Rejection, Reply};

type SharedConfig = Arc<RwLock<config::ProxyConfig>>;
type BackendCache = Arc<DashMap<String, Client>>;

pub async fn run_server(
    config: SharedConfig,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    // Parse the socket address
    let addr = SocketAddr::from_str(&config.read().await.listen_addr)
        .map_err(|e| std::io::Error::new(std::io::ErrorKind::InvalidInput, e))?;

    let backend_cache: BackendCache = Arc::new(DashMap::new());

    // Create the warp filter
    let routes = warp::any()
        .and(warp::path::full())
        .and(warp::method())
        .and(warp::header::headers_cloned())
        .and(
            warp::filters::query::raw()
                .or(warp::any().map(String::new))
                .unify(),
        )
        .and(warp::body::bytes())
        .and(with_config(config.clone()))
        .and(with_cache(backend_cache.clone()))
        .and_then(handle_request);

    // Start the server with graceful shutdown
    let (_, server) = warp::serve(routes).bind_with_graceful_shutdown(addr, async {
        shutdown_signal().await;
    });

    tracing::info!("HTTP proxy listening on {}", addr);
    server.await;
    Ok(())
}

fn with_config(
    config: SharedConfig,
) -> impl Filter<Extract = (SharedConfig,), Error = Infallible> + Clone {
    warp::any().map(move || config.clone())
}

fn with_cache(
    cache: BackendCache,
) -> impl Filter<Extract = (BackendCache,), Error = Infallible> + Clone {
    warp::any().map(move || cache.clone())
}

// Convert warp/http types to reqwest types
fn convert_method(method: warp::http::Method) -> reqwest::Method {
    match method.as_str() {
        "GET" => reqwest::Method::GET,
        "POST" => reqwest::Method::POST,
        "PUT" => reqwest::Method::PUT,
        "DELETE" => reqwest::Method::DELETE,
        "HEAD" => reqwest::Method::HEAD,
        "OPTIONS" => reqwest::Method::OPTIONS,
        "CONNECT" => reqwest::Method::CONNECT,
        "PATCH" => reqwest::Method::PATCH,
        "TRACE" => reqwest::Method::TRACE,
        _ => {
            reqwest::Method::from_bytes(method.as_str().as_bytes()).unwrap_or(reqwest::Method::GET)
        }
    }
}

fn convert_headers(headers: &HeaderMap) -> reqwest::header::HeaderMap {
    let mut reqwest_headers = reqwest::header::HeaderMap::new();
    for (name, value) in headers.iter() {
        if let Ok(reqwest_name) = reqwest::header::HeaderName::from_bytes(name.as_str().as_bytes())
        {
            if let Ok(reqwest_value) = reqwest::header::HeaderValue::from_bytes(value.as_bytes()) {
                reqwest_headers.insert(reqwest_name, reqwest_value);
            }
        }
    }
    reqwest_headers
}

async fn handle_request(
    path: FullPath,
    method: warp::http::Method,
    headers: HeaderMap,
    query: String,
    body: bytes::Bytes,
    config: SharedConfig,
    backend_cache: BackendCache,
) -> Result<impl Reply, Rejection> {
    let start = Instant::now();
    let path_str = path.as_str();

    tracing::info!("Processing request for path: {}", path_str);

    // Get route configuration with priority handling
    let route = {
        let config_guard = config.read().await;

        // Normalize the request path
        let normalized_path = path_str.trim_end_matches('/');
        tracing::info!("Normalized path: {}", normalized_path);

        // Find all matching routes
        let mut matching_routes: Vec<_> = config_guard
            .routes
            .iter()
            .filter_map(|(route_path, route)| {
                let normalized_route = route_path.trim_end_matches('/');

                let is_match = if route_path == "/" {
                    true
                } else {
                    normalized_path == normalized_route
                        || normalized_path.starts_with(&format!("{}/", normalized_route))
                };

                if is_match {
                    Some((
                        route_path.to_string(),
                        route.clone(),
                        normalized_route.matches('/').count(),
                        normalized_route.len(),
                    ))
                } else {
                    None
                }
            })
            .collect();

        matching_routes.sort_by(|a, b| {
            let a_priority = a.1.priority.unwrap_or(0);
            let b_priority = b.1.priority.unwrap_or(0);

            b_priority
                .cmp(&a_priority)
                .then(b.2.cmp(&a.2))
                .then(b.3.cmp(&a.3))
        });

        matching_routes
            .into_iter()
            .next()
            .ok_or_else(|| {
                let err = format!("No route found for path: {}", normalized_path);
                tracing::error!("{}", err);
                warp::reject::custom(RouteNotFound)
            })
            .map(|(route_path, route_config, _, _)| (route_path, route_config))?
    };

    // Get or create backend client
    let client = backend_cache
        .entry(route.1.upstream.clone())
        .or_insert_with(|| {
            Client::builder()
                .timeout(std::time::Duration::from_secs(30))
                .build()
                .expect("Failed to create HTTP client")
        })
        .value()
        .clone();

    // Parse upstream URI
    let upstream_uri = reqwest::Url::from_str(&route.1.upstream)
        .map_err(|_| warp::reject::custom(InvalidUpstreamUrl))?;

    // Build the final URL
    let mut final_url = upstream_uri.clone();

    // Handle path joining properly
    let upstream_path = upstream_uri.path().trim_end_matches('/');

    // Strip the matching route prefix from the request path
    let request_path = if route.0 == "/" {
        path_str
    } else {
        &path_str[route.0.len()..]
    }
    .trim_start_matches('/');

    // If upstream path is not empty and not just "/", combine it with request path
    let final_path = if upstream_path.is_empty() || upstream_path == "/" {
        format!("/{}", request_path)
    } else {
        format!("{}/{}", upstream_path, request_path)
    }
    .trim_end_matches('/')
    .to_string();

    final_url.set_path(&final_path);

    // Handle query string properly - strip any leading '?' if present
    if !query.is_empty() {
        let clean_query = query.trim_start_matches('?');
        if !clean_query.is_empty() {
            final_url.set_query(Some(clean_query));
        }
    }

    tracing::info!("Forwarding to upstream URL: {}", final_url);

    // Send request with timeout and retry logic
    let timeout = route.1.timeout_ms.unwrap_or(3000);
    let retry_count = route.1.retry_count.unwrap_or(2);

    let mut response = None;
    for attempt in 0..=retry_count {
        let mut req_builder = client
            .request(convert_method(method.clone()), final_url.clone())
            .timeout(std::time::Duration::from_millis(timeout))
            .headers(convert_headers(&headers))
            .body(body.clone());

        // Handle Host header based on preserve_host_header setting
        if !route.1.preserve_host_header.unwrap_or(false) {
            // Only set the host header to upstream host if we're not preserving the original
            if let Some(host) = final_url.host_str() {
                if let Ok(host_value) = reqwest::header::HeaderValue::from_str(host) {
                    req_builder = req_builder.header(reqwest::header::HOST, host_value);
                }
            }
        }

        match req_builder.send().await {
            Ok(resp) => {
                response = Some(resp);
                counter!("proxy.attempt.success", 1);
                break;
            }
            Err(e) => {
                tracing::warn!("Request failed (attempt {}): {}", attempt + 1, e);
                counter!("proxy.attempt.failure", 1);
            }
        }
    }

    // Record metrics
    let duration = start.elapsed();
    histogram!("proxy.request.duration", duration.as_secs_f64());
    counter!(
        "proxy.request.priority",
        route.1.priority.unwrap_or(0) as u64
    );

    match response {
        Some(resp) => {
            counter!("proxy.request.success", 1);
            tracing::info!(
                "Successfully proxied request for path: {} -> {}",
                path_str,
                final_url
            );

            // Convert reqwest response to warp response
            let status = resp.status().as_u16();
            let mut builder = warp::http::Response::builder().status(status);

            // Convert response headers
            if let Some(headers) = builder.headers_mut() {
                for (key, value) in resp.headers() {
                    if let Ok(name) =
                        warp::http::header::HeaderName::from_bytes(key.as_str().as_bytes())
                    {
                        if let Ok(val) =
                            warp::http::header::HeaderValue::from_bytes(value.as_bytes())
                        {
                            headers.insert(name, val);
                        }
                    }
                }
            }

            let body_bytes = resp
                .bytes()
                .await
                .map_err(|_| warp::reject::custom(UpstreamError))?;

            Ok(builder
                .body(body_bytes)
                .map_err(|_| warp::reject::custom(ResponseError))?)
        }
        None => {
            counter!("proxy.request.error", 1);
            tracing::error!("Failed to proxy request for path: {}", path_str);
            Ok(warp::http::Response::builder()
                .status(503)
                .body("Service Unavailable".into())
                .unwrap())
        }
    }
}

async fn shutdown_signal() {
    tokio::signal::ctrl_c()
        .await
        .expect("Failed to install CTRL+C signal handler");
}

// Custom rejection types
#[derive(Debug)]
struct RouteNotFound;
impl warp::reject::Reject for RouteNotFound {}

#[derive(Debug)]
struct InvalidUpstreamUrl;
impl warp::reject::Reject for InvalidUpstreamUrl {}

#[derive(Debug)]
struct UpstreamError;
impl warp::reject::Reject for UpstreamError {}

#[derive(Debug)]
struct ResponseError;
impl warp::reject::Reject for ResponseError {}

$$--GLUE--$$
.\src\lib.rs
$$--GLUE--$$
// src/lib.rs
use anyhow::Result;
use std::sync::Arc;
use tokio::sync::RwLock;

pub mod config;
pub mod metrics;
pub mod http_proxy;
pub mod tcp_proxy;  // TCP proxy module
pub mod udp_proxy;  // UDP proxy module

/// The main Router struct that manages all proxy services
pub struct Router {
    config: Arc<RwLock<config::ProxyConfig>>,
}

impl Router {
    /// Create a new Router with the provided configuration
    pub fn new(config: config::ProxyConfig) -> Self {
        Router {
            config: Arc::new(RwLock::new(config)),
        }
    }

    /// Create a new Router by loading configuration from a file
    pub fn from_file(config_path: &str) -> Result<Self> {
        let config = config::load_config(config_path)?;
        Ok(Router::new(config))
    }

    /// Start the router service with all enabled proxies
    pub async fn start(&self) -> Result<()> {
        // Initialize metrics
        metrics::init_metrics()?;

        let config = self.config.read().await.clone();

        // Check for database routes that should be handled as TCP
        let has_db_routes = config.routes.iter().any(|(_, route)| {
            config::is_likely_database(route)
        });

        // Check for UDP routes
        let has_udp_routes = config.routes.iter().any(|(_, route)| {
            route.is_udp.unwrap_or(false)
        });

        // Start TCP proxy if enabled or if database routes are detected
        if config.tcp_proxy.enabled || has_db_routes {
            tracing::info!("TCP proxy support enabled");
            let tcp_config = self.config.clone();
            
            // Spawn TCP proxy server in a separate task
            tokio::spawn(async move {
                let tcp_proxy = tcp_proxy::TcpProxyServer::new(tcp_config).await;
                if let Err(e) = tcp_proxy.run(&config.tcp_proxy.listen_addr).await {
                    tracing::error!("TCP proxy server error: {}", e);
                }
            });
        }
        
        // Start UDP proxy if enabled or if UDP routes are detected
        if config.tcp_proxy.udp_enabled || has_udp_routes {
            tracing::info!("UDP proxy support enabled");
            let udp_config = self.config.clone();
            
            // Use the same address as TCP proxy by default
            let udp_listen_addr = config.tcp_proxy.udp_listen_addr.clone();
            
            // Spawn UDP proxy server in a separate task
            tokio::spawn(async move {
                let udp_proxy = udp_proxy::UdpProxyServer::new(udp_config);
                if let Err(e) = udp_proxy.run(&udp_listen_addr).await {
                    tracing::error!("UDP proxy server error: {}", e);
                }
            });
        }

        // Start the HTTP proxy server
        http_proxy::run_server(self.config.clone())
            .await
            .map_err(|e| anyhow::anyhow!("HTTP Server error: {}", e))?;

        Ok(())
    }
}

// Re-export types for easier usage
pub use config::{ProxyConfig, RouteConfig, TcpProxyConfig};
$$--GLUE--$$
.\src\main.rs
$$--GLUE--$$
// src/main.rs
use anyhow::Result;
use harbr_router::{Router, ProxyConfig, RouteConfig, TcpProxyConfig};

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize logging
    tracing_subscriber::fmt()
        .with_env_filter("info,harbr_router=debug")
        .init();

    // Load configuration from file by default
    let config_path = std::env::var("CONFIG_FILE").unwrap_or_else(|_| "config.yml".to_string());
    let router = Router::from_file(&config_path)?;

    // Start the router
    router.start().await?;

    Ok(())
}
$$--GLUE--$$
.\src\metrics.rs
$$--GLUE--$$
use anyhow::Result;
use metrics_exporter_prometheus::PrometheusBuilder;

pub fn init_metrics() -> Result<()> {
    let builder = PrometheusBuilder::new();
    builder.install()?;
    Ok(())
}

$$--GLUE--$$
.\src\tcp_proxy.rs
$$--GLUE--$$
// src/tcp_proxy.rs
use crate::config::ProxyConfig;
use dashmap::DashMap;
use metrics::{counter, histogram};
use std::io;
use std::net::SocketAddr;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::io::{AsyncReadExt, AsyncWriteExt};
use tokio::net::{TcpListener, TcpStream};
use tokio::sync::RwLock;
use tokio::time::timeout;

type SharedConfig = Arc<RwLock<ProxyConfig>>;
type ConnectionCache = Arc<DashMap<String, Vec<(TcpStream, Instant)>>>;

pub struct TcpProxyServer {
    config: SharedConfig,
    connection_cache: ConnectionCache,
    max_idle_time: Duration,
    pooled_connections: bool,
}

impl TcpProxyServer {
    pub async fn new(config: SharedConfig) -> Self {
        let max_idle_time_secs = {
            let cfg = config.read().await;
            cfg.tcp_proxy.max_idle_time_secs
        };
        Self {
            config,
            connection_cache: Arc::new(DashMap::new()),
            max_idle_time: Duration::from_secs(max_idle_time_secs),
            pooled_connections: true,
        }
    }
    pub async fn run(&self, addr: &str) -> io::Result<()> {
        let listener = TcpListener::bind(addr).await?;
        tracing::info!("TCP proxy listening on {}", addr);

        // Spawn a task to periodically clean idle connections
        let cache = self.connection_cache.clone();
        let max_idle = self.max_idle_time;
        tokio::spawn(async move {
            loop {
                TcpProxyServer::clean_idle_connections(cache.clone(), max_idle).await;
                tokio::time::sleep(Duration::from_secs(30)).await;
            }
        });

        loop {
            let (client_stream, client_addr) = match listener.accept().await {
                Ok(connection) => connection,
                Err(e) => {
                    tracing::error!("Failed to accept connection: {}", e);
                    continue;
                }
            };

            tracing::info!("Accepted connection from {}", client_addr);

            // Clone required resources for the handler task
            let config = self.config.clone();
            let cache = self.connection_cache.clone();
            let max_idle = self.max_idle_time;
            let pooled = self.pooled_connections;

            // Spawn a task to handle the connection
            tokio::spawn(async move {
                if let Err(e) = Self::handle_connection(client_stream, client_addr, config, cache, max_idle, pooled).await {
                    tracing::error!("Connection error: {}", e);
                }
            });
        }
    }

    async fn handle_connection(
        mut client_stream: TcpStream,
        client_addr: SocketAddr,
        config: SharedConfig,
        connection_cache: ConnectionCache,
        max_idle_time: Duration,
        use_pooling: bool,
    ) -> io::Result<()> {
        // For simplicity, we'll use the first route as the default TCP route
        // In a real implementation, you'd need some way to determine the appropriate route
        // possibly by examining the first packet or using separate listeners for different services
        let route_config = {
            let config_guard = config.read().await;
            let first_route = config_guard.routes.iter().next();
            
            if let Some((_, route)) = first_route {
                route.clone()
            } else {
                return Err(io::Error::new(io::ErrorKind::NotFound, "No routes configured"));
            }
        };

        // Extract host and port from upstream URL
        let upstream_url = &route_config.upstream;
        let parts: Vec<&str> = upstream_url.split("://").collect();
        let host_port = if parts.len() > 1 {
            parts[1].split('/').next().unwrap_or(parts[1])
        } else {
            upstream_url.split('/').next().unwrap_or(upstream_url)
        };

        // Start timing
        let start = Instant::now();

        // Try to get a cached connection or create a new one
        let mut server_stream = if use_pooling {
            match Self::get_or_create_connection(host_port, &connection_cache, max_idle_time).await {
                Ok(stream) => stream,
                Err(e) => {
                    tracing::error!("Failed to connect to upstream {}: {}", host_port, e);
                    return Err(e);
                }
            }
        } else {
            match TcpStream::connect(host_port).await {
                Ok(stream) => stream,
                Err(e) => {
                    tracing::error!("Failed to connect to upstream {}: {}", host_port, e);
                    return Err(e);
                }
            }
        };

        // Set up timeout based on route configuration
        let timeout_ms = route_config.timeout_ms.unwrap_or(5000);
        let timeout_duration = Duration::from_millis(timeout_ms);

        // Bidirectional copy with timeout
        let (mut client_read, mut client_write) = client_stream.split();
        let (mut server_read, mut server_write) = server_stream.split();

        // Buffer for data transfer
        let mut buffer = vec![0u8; 65536]; // 64K buffer

        // Process data in both directions
        loop {
            // Read from client with timeout
            let read_result = match timeout(timeout_duration, client_read.read(&mut buffer)).await {
                Ok(result) => result,
                Err(_) => {
                    tracing::warn!("Client read timeout from {}", client_addr);
                    counter!("tcp_proxy.timeout", 1);
                    break;
                }
            };

            // Process read result
            match read_result {
                Ok(0) => {
                    // Client closed the connection
                    break;
                }
                Ok(n) => {
                    // Write data to server
                    if let Err(e) = server_write.write_all(&buffer[..n]).await {
                        tracing::error!("Failed to write to server: {}", e);
                        break;
                    }
                }
                Err(e) => {
                    tracing::error!("Failed to read from client: {}", e);
                    break;
                }
            }

            // Read from server with timeout
            let read_result = match timeout(timeout_duration, server_read.read(&mut buffer)).await {
                Ok(result) => result,
                Err(_) => {
                    tracing::warn!("Server read timeout");
                    counter!("tcp_proxy.timeout", 1);
                    break;
                }
            };

            // Process read result
            match read_result {
                Ok(0) => {
                    // Server closed the connection
                    break;
                }
                Ok(n) => {
                    // Write data to client
                    if let Err(e) = client_write.write_all(&buffer[..n]).await {
                        tracing::error!("Failed to write to client: {}", e);
                        break;
                    }
                }
                Err(e) => {
                    tracing::error!("Failed to read from server: {}", e);
                    break;
                }
            }
        }

        // Record metrics
        let duration = start.elapsed();
        histogram!("tcp_proxy.connection.duration", duration.as_secs_f64());
        counter!("tcp_proxy.connection.completed", 1);
        
        // If we're using connection pooling and the connection is still good, return it to the pool
        // This would be a more complex check in a real implementation
        if use_pooling {
            // Recombine the split parts (we can't actually do this easily, so this is simplified)
            // In a real implementation, you'd need a different approach to reuse the connection
            tracing::info!("Connection completed, not returning to pool in this simplified example");
        }

        Ok(())
    }

    async fn get_or_create_connection(
        target: &str, 
        cache: &ConnectionCache,
        max_idle_time: Duration
    ) -> io::Result<TcpStream> {
        // Try to get an existing connection from the pool
        if let Some(mut connections) = cache.get_mut(target) {
            while let Some((conn, timestamp)) = connections.pop() {
                if timestamp.elapsed() < max_idle_time {
                    tracing::debug!("Reusing cached connection to {}", target);
                    return Ok(conn);
                }
                // Connection too old, discard it
                tracing::debug!("Discarding expired connection to {}", target);
            }
        }

        // No valid connection found, create a new one
        tracing::debug!("Creating new connection to {}", target);
        let stream = TcpStream::connect(target).await?;
        counter!("tcp_proxy.connection.new", 1);
        Ok(stream)
    }

    async fn clean_idle_connections(cache: ConnectionCache, max_idle_time: Duration) {
        let now = Instant::now();
        
        for mut entry in cache.iter_mut() {
            let connections = entry.value_mut();
            
            // Remove expired connections
            connections.retain(|(_, timestamp)| {
                now.duration_since(*timestamp) < max_idle_time
            });
            
            tracing::debug!("{} connections remaining for {}", connections.len(), entry.key());
        }
    }
}
$$--GLUE--$$
.\src\udp_proxy.rs
$$--GLUE--$$
// src/udp_proxy.rs
use crate::config::{ProxyConfig, RouteConfig};
use dashmap::DashMap;
use metrics::{counter, histogram};
use std::io;
use std::net::SocketAddr;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::net::UdpSocket;
use tokio::sync::{mpsc, RwLock};
use tokio::time::timeout;

type SharedConfig = Arc<RwLock<ProxyConfig>>;
type DestinationMap = Arc<DashMap<SocketAddr, String>>;

const MAX_DATAGRAM_SIZE: usize = 65507; // Maximum UDP datagram size

pub struct UdpProxyServer {
    config: SharedConfig,
    destination_map: DestinationMap,
}

impl UdpProxyServer {
    pub fn new(config: SharedConfig) -> Self {
        Self {
            config,
            destination_map: Arc::new(DashMap::new()),
        }
    }

    pub async fn run(&self, addr: &str) -> io::Result<()> {
        // Initialize the UDP socket for listening
        let socket = Arc::new(UdpSocket::bind(addr).await?);
        tracing::info!("UDP proxy listening on {}", addr);

        // Create a channel for response handling
        let (tx, mut rx) = mpsc::channel::<(Vec<u8>, SocketAddr, SocketAddr)>(1000);
        
        // Spawn a task for handling responses
        let response_socket = socket.clone();
        tokio::spawn(async move {
            while let Some((data, client_addr, _)) = rx.recv().await {
                match response_socket.send_to(&data, client_addr).await {
                    Ok(sent) => {
                        tracing::debug!("Sent {} bytes response to {}", sent, client_addr);
                        counter!("udp_proxy.datagram.response_sent", 1);
                    }
                    Err(e) => {
                        tracing::error!("Error sending response to {}: {}", client_addr, e);
                        counter!("udp_proxy.error", 1);
                    }
                }
            }
        });

        // Buffer for receiving datagrams
        let mut buf = vec![0u8; MAX_DATAGRAM_SIZE];

        // Main processing loop
        loop {
            // Set up timeout based on global config
            let timeout_ms = {
                let config_guard = self.config.read().await;
                config_guard.global_timeout_ms
            };
            let timeout_duration = Duration::from_millis(timeout_ms);

            // Try to receive a datagram with timeout
            let receive_result = match timeout(
                timeout_duration, 
                socket.recv_from(&mut buf)
            ).await {
                Ok(result) => result,
                Err(_) => {
                    // Timeout occurred, just continue the loop
                    counter!("udp_proxy.timeout", 1);
                    continue;
                }
            };

            // Process the received datagram
            match receive_result {
                Ok((size, client_addr)) => {
                    tracing::debug!("Received {} bytes from {}", size, client_addr);
                    let start = Instant::now();
                    counter!("udp_proxy.datagram.received", 1);

                    // Clone required resources for the handler task
                    let request_socket = socket.clone();
                    let config_clone = self.config.clone();
                    let destination_map = self.destination_map.clone();
                    let datagram = buf[..size].to_vec();
                    let tx_clone = tx.clone();

                    // Process the datagram in a separate task
                    tokio::spawn(async move {
                        if let Err(e) = Self::handle_datagram(
                            request_socket,
                            client_addr,
                            datagram,
                            config_clone,
                            destination_map,
                            tx_clone,
                            start
                        ).await {
                            tracing::error!("Error handling UDP datagram: {}", e);
                            counter!("udp_proxy.error", 1);
                        }
                    });
                }
                Err(e) => {
                    tracing::error!("Error receiving UDP datagram: {}", e);
                    counter!("udp_proxy.error", 1);
                }
            }
        }
    }

    async fn handle_datagram(
        socket: Arc<UdpSocket>,
        client_addr: SocketAddr,
        datagram: Vec<u8>,
        config: SharedConfig,
        destination_map: DestinationMap,
        tx: mpsc::Sender<(Vec<u8>, SocketAddr, SocketAddr)>,
        start_time: Instant,
    ) -> io::Result<()> {
        // Determine the route and upstream destination
        let destination = {
            // Check if we already have a mapping for this client
            if let Some(dest) = destination_map.get(&client_addr) {
                dest.clone()
            } else {

                // ToDo: For UDP, we need to determine the route based on client info
                // or the contents of the first packet
                // This is a simplified implementation
              
                // For now, use the first UDP route in the config
                let config_guard = config.read().await;
                let udp_route = config_guard.routes.iter()
                    .find(|(_, route)| {
                        route.is_udp.unwrap_or(false)
                    });

                if let Some((_, route)) = udp_route {
                    // Extract host and port from the upstream URL
                    let upstream_url = &route.upstream;
                    let dest = extract_host_port(upstream_url);
                    
                    // Store the mapping for future datagrams from this client
                    destination_map.insert(client_addr, dest.clone());
                    
                    dest
                } else {
                    return Err(io::Error::new(
                        io::ErrorKind::NotFound,
                        "No UDP route configured",
                    ));
                }
            }
        };

        // Get timeout from configuration
        let timeout_ms = {
            let config_guard = config.read().await;
            let default_timeout = config_guard.global_timeout_ms;

            // Try to find a specific route config for this destination
            config_guard.routes.iter()
                .find(|(_, route)| {
                    extract_host_port(&route.upstream) == destination
                })
                .and_then(|(_, route)| route.timeout_ms)
                .unwrap_or(default_timeout)
        };

        // Forward the datagram to the destination
        let dest_addr = destination.parse::<SocketAddr>().map_err(|e| {
            io::Error::new(io::ErrorKind::InvalidInput, format!("Invalid destination address: {}", e))
        })?;
        
        // Set up timeout for the send operation
        match timeout(
            Duration::from_millis(timeout_ms),
            socket.send_to(&datagram, dest_addr)
        ).await {
            Ok(Ok(bytes_sent)) => {
                tracing::debug!("Forwarded {} bytes to {}", bytes_sent, dest_addr);
                counter!("udp_proxy.datagram.forwarded", 1);
            }
            Ok(Err(e)) => {
                tracing::error!("Error forwarding UDP datagram: {}", e);
                counter!("udp_proxy.error", 1);
                return Err(e);
            }
            Err(_) => {
                tracing::warn!("Timeout forwarding UDP datagram to {}", dest_addr);
                counter!("udp_proxy.timeout", 1);
                return Err(io::Error::new(
                    io::ErrorKind::TimedOut,
                    "Timed out forwarding UDP datagram",
                ));
            }
        }

        // Create a new socket for receiving responses
        // We need a separate socket because we can't listen on the same socket we're sending from
        // without more complex socket sharing logic
        let bind_addr = if socket.local_addr()?.ip().is_unspecified() {
            format!("0.0.0.0:0")
        } else {
            format!("{}:0", socket.local_addr()?.ip())
        };
        
        let response_socket = UdpSocket::bind(bind_addr).await?;
        
        // Connected UDP sockets can only receive from the specific address they're connected to
        response_socket.connect(dest_addr).await?;
        
        // Set up a task to wait for a response
        let mut response_buf = vec![0u8; MAX_DATAGRAM_SIZE];
        match timeout(
            Duration::from_millis(timeout_ms),
            response_socket.recv(&mut response_buf)
        ).await {
            Ok(Ok(size)) => {
                // Forward the response back to the client through the channel
                if let Err(e) = tx.send((
                    response_buf[..size].to_vec(),
                    client_addr,
                    dest_addr
                )).await {
                    tracing::error!("Failed to send response through channel: {}", e);
                    counter!("udp_proxy.error", 1);
                }
            }
            Ok(Err(e)) => {
                tracing::error!("Error receiving response: {}", e);
                counter!("udp_proxy.error", 1);
            }
            Err(_) => {
                tracing::debug!("No response received within timeout");
                counter!("udp_proxy.timeout", 1);
            }
        }

        // Record metrics
        let duration = start_time.elapsed();
        histogram!("udp_proxy.datagram.duration", duration.as_secs_f64());

        Ok(())
    }
}

// Helper function to extract host:port from a URL
fn extract_host_port(url: &str) -> String {
    // Parse out protocol
    let url_without_protocol = url.split("://").nth(1).unwrap_or(url);
    
    // Extract host:port part
    url_without_protocol.split('/').next().unwrap_or(url_without_protocol).to_string()
}
